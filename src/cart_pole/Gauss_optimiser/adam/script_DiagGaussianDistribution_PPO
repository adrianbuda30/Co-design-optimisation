import torch
import torch.distributions as D
import torch.nn.functional as F
import numpy as np
import torch.optim as optim

class DesignDistribution_log:
    def __init__(self, initial_mean, initial_std, lr_mean=0.1, lr_std=0.1, epsilon=0.2):
        self.mean = torch.tensor(initial_mean, dtype=torch.float32, requires_grad=True)
        self.std = torch.tensor(initial_std, dtype=torch.float32, requires_grad=True)
        
        self.optimizer = optim.Adam([self.mean, self.std], lr=lr_mean)
        self.epsilon = epsilon

    def update_distribution(self, batch_rewards, batch_samples, batch_probs):

        mean_rewards = torch.mean(torch.tensor(batch_rewards, dtype=torch.float32))

        for i in range(len(batch_rewards)):
            self.optimizer.zero_grad()

            sample = torch.tensor(batch_samples[i], dtype=torch.float32)
            current_prob = D.Normal(self.mean, F.softplus(self.std)).log_prob(sample).exp().prod()
            old_prob = batch_probs[i]
            ratio = current_prob / old_prob
            surrogate1 = ratio * mean_rewards
            surrogate2 = torch.clamp(ratio, 1 - self.epsilon, 1 + self.epsilon) * mean_rewards
            loss = -torch.min(surrogate1, surrogate2).mean()
            loss.backward()
            self.optimizer.step()

    def sample_design(self):
        distribution = D.Normal(self.mean, F.softplus(self.std))
        sample = distribution.sample()
        prob = distribution.log_prob(sample).exp().prod()
        return sample.detach(), prob.item()

def reward_function(sampled_design):
    reward = -torch.norm((sampled_design - torch.tensor([10.0, 20.0, 30.0, 40.0], dtype=torch.float32)))
    return reward.item()

initial_mean = 25 * np.random.rand(4).astype(np.float32)
initial_std = np.ones(4, dtype=np.float32) * 100.0  # Initialize std deviation as you prefer

design_dist = DesignDistribution_log(initial_mean, initial_std)

num_episodes = 100000
batch_size = 1

for i in range(0, num_episodes, batch_size):
    batch_rewards = []
    batch_samples = []
    batch_probs = []

    for _ in range(batch_size):
        sampled_design, prob = design_dist.sample_design()
        reward = reward_function(sampled_design)
        
        batch_samples.append(sampled_design.numpy())
        batch_rewards.append(reward)
        batch_probs.append(prob)

    design_dist.update_distribution(batch_rewards, batch_samples, batch_probs)
    
    print(f"mean: {design_dist.mean} reward: {np.mean(batch_rewards)}")
